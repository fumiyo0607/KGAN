{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import required module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルを復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model_last-fm_epoch=300'\n",
    "meta_file_name = 'weights-299.meta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_last-fm_epoch=300/weights-299\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph('./{}/{}'.format(model_file, meta_file_name))\n",
    "\n",
    "# モデルの復元\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./' + model_file + '/'))\n",
    "# グラフを復元\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embed = graph.get_tensor_by_name(\"user_embed:0\")\n",
    "entity_embed = graph.get_tensor_by_name(\"entity_embed:0\")\n",
    "relation_embed = graph.get_tensor_by_name(\"relation_embed:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測結果をロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = '../Analysis/each_user_result/'\n",
    "file_name = 'last-fm_each_user_ret_epoch=0.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 0, 'recall': array([0.08510638, 0.12765957, 0.14893617, 0.14893617, 0.14893617]), 'precision': array([0.2       , 0.15      , 0.11666667, 0.0875    , 0.07      ]), 'ndcg': array([0.34691272, 0.4642606 , 0.51347782, 0.51347782, 0.51347782]), 'hit_ratio': array([1., 1., 1., 1., 1.]), 'auc': 0.0, 'top_N_items': [(1085, 11.455713), (10778, 11.330286), (23493, 11.135474), (11184, 11.129554), (11211, 10.938282), (8523, 10.843382), (2237, 10.800094), (8422, 10.597556), (10936, 10.547527), (9491, 10.531397), (19439, 10.492456), (10874, 10.43594), (9454, 10.372491), (9492, 10.35069), (14037, 10.296987), (7140, 10.198753), (23496, 10.131675), (7536, 10.083475), (8524, 9.937377), (9493, 9.814255)]}\n"
     ]
    }
   ],
   "source": [
    "with open (saved_path + file_name, 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rec_items = defaultdict()\n",
    "\n",
    "for user, ret in result.items():\n",
    "    items = dict(ret['top_N_items'])\n",
    "    items = items.keys()\n",
    "    \n",
    "    user_rec_items[user]  = list(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Score の算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kge_dim = 64\n",
    "\n",
    "def _generate_transE_score( h, t, r):\n",
    "        \n",
    "        embeddings = tf.concat([user_embed, entity_embed], axis=0)\n",
    "        embeddings = tf.expand_dims(embeddings, 1)\n",
    "\n",
    "        h_e = tf.nn.embedding_lookup(embeddings, h)\n",
    "        t_e = tf.nn.embedding_lookup(embeddings, t)\n",
    "        \n",
    "        # relation embeddings: batch_size * kge_dim\n",
    "        r_e = tf.nn.embedding_lookup(relation_embed, r)\n",
    "\n",
    "        '''\n",
    "    \n",
    "        # relation transform weights: batch_size * kge_dim * emb_dim\n",
    "        trans_M = tf.nn.embedding_lookup(trans_W, r)\n",
    "\n",
    "        # batch_size * 1 * kge_dim -> batch_size * kge_dim\n",
    "        h_e = tf.reshape(tf.matmul(h_e, trans_M), [-1, self.kge_dim])\n",
    "        t_e = tf.reshape(tf.matmul(t_e, trans_M), [-1, self.kge_dim])\n",
    "        '''\n",
    "\n",
    "        # l2-normalize\n",
    "        h_e = tf.math.l2_normalize(h_e, axis=1)\n",
    "        r_e = tf.math.l2_normalize(r_e, axis=1)\n",
    "        t_e = tf.math.l2_normalize(t_e, axis=1)\n",
    "\n",
    "        kg_score = tf.reduce_sum(tf.multiply(t_e, tf.tanh(h_e + r_e)), 1)\n",
    "\n",
    "        return kg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'math'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-edb12c545bf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkg_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_generate_transE_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-15521f246507>\u001b[0m in \u001b[0;36m_generate_transE_score\u001b[1;34m(h, t, r)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# l2-normalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mh_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mr_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mt_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'math'"
     ]
    }
   ],
   "source": [
    "kg_score = _generate_transE_score(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    sess.run(kg_score)\n",
    "    kg_score = kg_score.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2792517], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%conda` not found.\n"
     ]
    }
   ],
   "source": [
    "% conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
