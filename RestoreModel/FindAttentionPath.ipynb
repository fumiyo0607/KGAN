{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import required module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測結果をロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = './result_1114/'\n",
    "file_name = 'each_user_ret_epoch=19.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (saved_path + file_name, 'rb') as f:\n",
    "    result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rec_items = defaultdict()\n",
    "\n",
    "for user, ret in result.items():\n",
    "    items = dict(ret['top_N_items'])\n",
    "    items = items.keys()\n",
    "    \n",
    "    user_rec_items[user]  = list(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_num:23566\n"
     ]
    }
   ],
   "source": [
    "users =  user_rec_items.keys()\n",
    "USER_NUM = len(users)\n",
    "print('user_num:{}'.format(USER_NUM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(users)\n",
    "top_users = users[:100]\n",
    "worst_users = users[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正規化済みの Attention Score のロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = './result_1114/'\n",
    "file_name = 'attention_score_epoch=19.pickle'\n",
    "\n",
    "with open (saved_path + file_name, 'rb') as f:\n",
    "    attention_score = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129955, 129955)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# attention_score[e_h, e_t] として Attention Score にアクセスできる\n",
    "attention_score = sp.csr_matrix(attention_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph のデータをロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = '../Data/last-fm/'\n",
    "file_name = 'kg_final.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_h</th>\n",
       "      <th>r</th>\n",
       "      <th>e_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12700</td>\n",
       "      <td>0</td>\n",
       "      <td>48123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18104</td>\n",
       "      <td>0</td>\n",
       "      <td>48123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25838</td>\n",
       "      <td>1</td>\n",
       "      <td>48124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41691</td>\n",
       "      <td>2</td>\n",
       "      <td>48125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9746</td>\n",
       "      <td>1</td>\n",
       "      <td>48126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     e_h  r    e_t\n",
       "0  12700  0  48123\n",
       "1  18104  0  48123\n",
       "2  25838  1  48124\n",
       "3  41691  2  48125\n",
       "4   9746  1  48126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_df = pd.read_csv(saved_path + file_name, sep=' ', header=None, names=('e_h','r','e_t'))\n",
    "kg_df = kg_df.drop_duplicates()\n",
    "kg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = '../Data/last-fm/'\n",
    "file_name  = 'train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = defaultdict(list)\n",
    "f = open(saved_path+file_name)\n",
    "line = f.readline()\n",
    "\n",
    "while line :\n",
    "\n",
    "    data = line.strip()\n",
    "    data_list = data.split()\n",
    "\n",
    "    user = data_list[0]\n",
    "    items = data_list[1:]\n",
    "    all_data[user] = items\n",
    "    \n",
    "    line = f.readline()\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [推薦アイテム→entity→インタラクションのあったアイテム] のパスを特定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_to_entity_attention_score(e_h, e_t):\n",
    "\n",
    "    e_h_idx = e_h + USER_NUM\n",
    "    e_t_idx = e_t + USER_NUM\n",
    "    att = attention_score[e_h_idx, e_t_idx]\n",
    "\n",
    "    return att\n",
    "\n",
    "def get_user_to_item_attention_score(user_id, item_id):\n",
    "\n",
    "    e_h_idx = user_id\n",
    "    e_t_idx = item_id + USER_NUM\n",
    "    att = attention_score[e_h_idx, e_t_idx]\n",
    "\n",
    "    return att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▊                                                                   | 17/100 [03:38<14:10, 10.24s/it]"
     ]
    }
   ],
   "source": [
    "rec_item_path = defaultdict(dict)\n",
    "\n",
    "users = [0]\n",
    "\n",
    "for user in tqdm(top_users):\n",
    "\n",
    "    rec_item_list = user_rec_items[user]\n",
    "    interacted_items = list(dict.fromkeys(all_data[str(user)]))\n",
    "\n",
    "    for rec_item_id in rec_item_list:\n",
    "\n",
    "        rec_item_entity_relation_df = kg_df[kg_df['e_h'] == rec_item_id]\n",
    "\n",
    "        entity_list = list(rec_item_entity_relation_df['e_t'])\n",
    "\n",
    "        for entity_id in entity_list:\n",
    "\n",
    "            target_rec_item_entity_relation_df = rec_item_entity_relation_df[rec_item_entity_relation_df['e_t']==entity_id]\n",
    "    \n",
    "            relation_list    = list(target_rec_item_entity_relation_df['r'])\n",
    "\n",
    "            for entity_to_rec_item_r in relation_list:\n",
    "\n",
    "                # attention score : entity to recommended item\n",
    "                entity_to_rec_item_att = get_entity_to_entity_attention_score(entity_id, rec_item_id)\n",
    "\n",
    "                item_entity_relation_df = kg_df[kg_df['e_t'] == entity_id]\n",
    "                head_items = list(item_entity_relation_df['e_h'])\n",
    "\n",
    "                interacted_item_entity_relation_df = item_entity_relation_df.query('e_h in {}'.format(interacted_items))\n",
    "\n",
    "                if len(interacted_item_entity_relation_df) > 0:\n",
    "\n",
    "                    e_h_list      = list(interacted_item_entity_relation_df['e_h'])\n",
    "                    e_t_list      = list(interacted_item_entity_relation_df['e_t'])\n",
    "                    relation_list = list(interacted_item_entity_relation_df['r'])\n",
    "\n",
    "                    for e_h, e_t, r in zip(e_h_list, e_t_list, relation_list):\n",
    "                        \n",
    "                        item_id          = e_h  # interacted item\n",
    "                        item_to_entity_r = r    # relation between interacted item and entity\n",
    "\n",
    "                        # consider item to entity to rec_item path\n",
    "                        if item_to_entity_r == entity_to_rec_item_r:\n",
    "                            \n",
    "                            # attention score : interacted item to entity\n",
    "                            item_to_entity_att = get_entity_to_entity_attention_score(item_id, entity_id)\n",
    "                    \n",
    "                            # attention score : user to interacted item\n",
    "                            user_to_item_att = get_user_to_item_attention_score(user, item_id)\n",
    "\n",
    "                            total_att_score = user_to_item_att + item_to_entity_att + entity_to_rec_item_att\n",
    "\n",
    "                            if not rec_item_id in rec_item_path[user] or ( total_att_score > max_att) :\n",
    "\n",
    "                                max_att = total_att_score \n",
    "\n",
    "                                rec_item_path[user][rec_item_id] =  {\n",
    "\n",
    "                                                        'total_att_score'    : total_att_score,\n",
    "                                                        'relation'           : item_to_entity_r,\n",
    "                                                        'item_id'            : item_id, \n",
    "                                                        'entity_id'          : entity_id, \n",
    "                                                        'rec_item_id'        : rec_item_id,\n",
    "                                                        'user_to_item'       : user_to_item_att,\n",
    "                                                        'item_to_entity'     : item_to_entity_att,\n",
    "                                                        'entity_to_rec_item' : entity_to_rec_item_att\n",
    "                                                    }\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './attention_path/'\n",
    "file_name = 'top_100_users_path.pickle'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "with open(save_path + file_name, mode='wb') as f:\n",
    "    pickle.dump(rec_item_path, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgat",
   "language": "python",
   "name": "kgat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
